# -*- coding: utf-8 -*-
"""Model_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mv0ywwqrGFGHq8WK-xoLpeFV_aTil2YI

**Membuat Model NLP menggunakan Tensorflow**

Nama : Astri Widyastiti

Id Dicoding : astriwidyastiti

Email : astriwidyastiti@gmail.com
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Import Data"""

import pandas as pd
data=pd.read_csv('/content/drive/MyDrive/Emotion_classify_Data.csv')
data.head()

data.shape

data.info()

"""# Membuat Variabel Dummy"""

category = pd.get_dummies(data.Emotion)
data_baru = pd.concat([data, category], axis=1)
data_baru = data_baru.drop(columns='Emotion')
data_baru

text = data_baru['Comment'].values
label = data_baru[['anger','fear','joy']].values

text

label

"""# Split Data"""

from sklearn.model_selection import train_test_split
text_latih, text_test, label_latih, label_test = train_test_split(text, label, test_size=0.2)

"""# Tokenization"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=1000, oov_token='x')
tokenizer.fit_on_texts(text_latih)
tokenizer.fit_on_texts(text_test)

sekuens_latih = tokenizer.texts_to_sequences(text_latih)
sekuens_test = tokenizer.texts_to_sequences(text_test)

pad_train=pad_sequences(sekuens_latih,
padding='post',
maxlen=50,
truncating='post')

pad_test=pad_sequences(sekuens_test,
padding='post',
maxlen=50,
truncating='post')
# pad_train = pad_sequences(sekuens_latih, maxlen=100)
# pad_test = pad_sequences(sekuens_test,  maxlen=100)

"""# Membuat Model"""

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=20000,output_dim=16),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(64,activation='relu'),
    tf.keras.layers.Dense(128,activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""# Callbacks"""

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=5,
    min_lr=1.5e-5
)

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0,
    patience=12,
    verbose=0,
    mode="auto",
    baseline=None,
    restore_best_weights=True)

"""# Menjalankan Model"""

num_epochs = 100
history = model.fit(pad_train, label_latih, epochs=num_epochs, batch_size=32,callbacks=[reduce_lr, early_stop],
                    validation_data=(pad_test, label_test),verbose=1)

loss, accuracy = model.evaluate(pad_test, label_test)
print(f"Loss: {loss}")
print(f"Accuracy: {accuracy}")

"""# Visualisasi Model"""

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(41)

plt.figure(figsize=(14, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()